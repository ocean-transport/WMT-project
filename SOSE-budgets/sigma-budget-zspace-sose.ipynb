{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\begin{equation*} \\frac{D \\sigma}{D t} = \\dot\\sigma_{\\theta} = \\frac{\\partial \\sigma_{\\theta}}{\\partial \\theta} \\dot\\theta + \\frac{\\partial \\sigma_{\\theta}}{\\partial S} \\dot S \\end{equation*}\n",
    "## **SOSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import GatewayCluster\n",
    "\n",
    "cluster = GatewayCluster()\n",
    "cluster.scale(10)\n",
    "#cluster.adapt(minimum=2, maximum=10)  # or cluster.scale(n) to a fixed size.\n",
    "client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>gateway://traefik-gcp-uscentral1b-prod-dask-gateway.prod:80/prod.5f54f51695074e1fb6924366fbcee4b5</li>\n",
       "  <li><b>Dashboard: </b><a href='/services/dask-gateway/clusters/prod.5f54f51695074e1fb6924366fbcee4b5/status' target='_blank'>/services/dask-gateway/clusters/prod.5f54f51695074e1fb6924366fbcee4b5/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>34.36 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tls://10.36.28.46:8786' processes=4 threads=8, memory=34.36 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import gcsfs\n",
    "import dask\n",
    "import dask.array as dsa\n",
    "import numpy as np\n",
    "import fsspec\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.core.options.set_options at 0x7efde85203d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr.set_options(display_style='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n",
      "/srv/conda/envs/notebook/lib/python3.8/site-packages/xarray/core/indexing.py:1361: PerformanceWarning: Slicing is producing a large chunk. To accept the large\n",
      "chunk and silence this warning, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': False}):\n",
      "    ...     array[indexer]\n",
      "\n",
      "To avoid creating the large chunks, set the option\n",
      "    >>> with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
      "    ...     array[indexer]\n",
      "  return self.array[key]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>&lt;xarray.Dataset&gt;\n",
       "Dimensions:                   (XC: 570, YC: 95, Z: 42, i: 95, i_g: 96, j: 50, j_g: 51, k: 50, k_l: 50, time: 715)\n",
       "Coordinates:\n",
       "  * time                      (time) datetime64[ns] 1992-01-15 ... 2015-12-14\n",
       "  * XC                        (XC) float32 295.08334 295.25 ... 29.75 29.916668\n",
       "  * YC                        (YC) float32 -77.87497 -77.7083 ... -62.2083\n",
       "  * Z                         (Z) float32 -5.0 -15.5 -27.0 ... -5325.0 -5575.0\n",
       "  * k                         (k) int64 0 1 2 3 4 5 6 7 ... 43 44 45 46 47 48 49\n",
       "  * k_l                       (k_l) int64 0 1 2 3 4 5 6 ... 43 44 45 46 47 48 49\n",
       "Dimensions without coordinates: i, i_g, j, j_g\n",
       "Data variables:\n",
       "    ETAN                      (time, YC, XC) float32 dask.array&lt;chunksize=(157, 95, 570), meta=np.ndarray&gt;\n",
       "    SALT                      (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    THETA                     (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    conv_horiz_adv_flux_SLT   (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    conv_horiz_diff_flux_SLT  (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    conv_vert_adv_flux_SLT    (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    conv_vert_diff_flux_SLT   (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    lin_fs_correction_SLT     (time, YC, XC) float32 dask.array&lt;chunksize=(157, 95, 570), meta=np.ndarray&gt;\n",
       "    surface_flux_conv_SLT     (time, YC, XC) float32 dask.array&lt;chunksize=(157, 95, 570), meta=np.ndarray&gt;\n",
       "    total_tendency_SLT_truth  (time, Z, YC, XC) float64 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    conv_horiz_adv_flux_TH    (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    conv_horiz_diff_flux_TH   (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    conv_vert_adv_flux_TH     (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    conv_vert_diff_flux_TH    (time, Z, YC, XC) float32 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    lin_fs_correction_TH      (time, YC, XC) float32 dask.array&lt;chunksize=(157, 95, 570), meta=np.ndarray&gt;\n",
       "    surface_flux_conv_TH      (time, YC, XC) float32 dask.array&lt;chunksize=(157, 95, 570), meta=np.ndarray&gt;\n",
       "    sw_flux_conv_TH           (time, YC, XC, Z) float32 dask.array&lt;chunksize=(157, 95, 570, 42), meta=np.ndarray&gt;\n",
       "    total_tendency_TH_truth   (time, Z, YC, XC) float64 dask.array&lt;chunksize=(157, 42, 95, 570), meta=np.ndarray&gt;\n",
       "    UVEL                      (time, k, j, i_g) float32 dask.array&lt;chunksize=(1, 50, 50, 67), meta=np.ndarray&gt;\n",
       "    VVEL                      (time, k, j_g, i) float32 dask.array&lt;chunksize=(1, 50, 51, 67), meta=np.ndarray&gt;\n",
       "    WVEL                      (time, k_l, j, i) float32 dask.array&lt;chunksize=(1, 50, 50, 67), meta=np.ndarray&gt;</pre>"
      ],
      "text/plain": [
       "<xarray.Dataset>\n",
       "Dimensions:                   (XC: 570, YC: 95, Z: 42, i: 95, i_g: 96, j: 50, j_g: 51, k: 50, k_l: 50, time: 715)\n",
       "Coordinates:\n",
       "  * time                      (time) datetime64[ns] 1992-01-15 ... 2015-12-14\n",
       "  * XC                        (XC) float32 295.08334 295.25 ... 29.75 29.916668\n",
       "  * YC                        (YC) float32 -77.87497 -77.7083 ... -62.2083\n",
       "  * Z                         (Z) float32 -5.0 -15.5 -27.0 ... -5325.0 -5575.0\n",
       "  * k                         (k) int64 0 1 2 3 4 5 6 7 ... 43 44 45 46 47 48 49\n",
       "  * k_l                       (k_l) int64 0 1 2 3 4 5 6 ... 43 44 45 46 47 48 49\n",
       "Dimensions without coordinates: i, i_g, j, j_g\n",
       "Data variables:\n",
       "    ETAN                      (time, YC, XC) float32 dask.array<chunksize=(157, 95, 570), meta=np.ndarray>\n",
       "    SALT                      (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    THETA                     (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    conv_horiz_adv_flux_SLT   (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    conv_horiz_diff_flux_SLT  (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    conv_vert_adv_flux_SLT    (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    conv_vert_diff_flux_SLT   (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    lin_fs_correction_SLT     (time, YC, XC) float32 dask.array<chunksize=(157, 95, 570), meta=np.ndarray>\n",
       "    surface_flux_conv_SLT     (time, YC, XC) float32 dask.array<chunksize=(157, 95, 570), meta=np.ndarray>\n",
       "    total_tendency_SLT_truth  (time, Z, YC, XC) float64 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    conv_horiz_adv_flux_TH    (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    conv_horiz_diff_flux_TH   (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    conv_vert_adv_flux_TH     (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    conv_vert_diff_flux_TH    (time, Z, YC, XC) float32 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    lin_fs_correction_TH      (time, YC, XC) float32 dask.array<chunksize=(157, 95, 570), meta=np.ndarray>\n",
       "    surface_flux_conv_TH      (time, YC, XC) float32 dask.array<chunksize=(157, 95, 570), meta=np.ndarray>\n",
       "    sw_flux_conv_TH           (time, YC, XC, Z) float32 dask.array<chunksize=(157, 95, 570, 42), meta=np.ndarray>\n",
       "    total_tendency_TH_truth   (time, Z, YC, XC) float64 dask.array<chunksize=(157, 42, 95, 570), meta=np.ndarray>\n",
       "    UVEL                      (time, k, j, i_g) float32 dask.array<chunksize=(1, 50, 50, 67), meta=np.ndarray>\n",
       "    VVEL                      (time, k, j_g, i) float32 dask.array<chunksize=(1, 50, 51, 67), meta=np.ndarray>\n",
       "    WVEL                      (time, k_l, j, i) float32 dask.array<chunksize=(1, 50, 50, 67), meta=np.ndarray>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords = xr.open_zarr(gcsfs.GCSMap('pangeo-tmp/stb2145/SOSE/datasets/coords_wg.zarr'))\n",
    "ds_tns = xr.open_zarr(gcsfs.GCSMap('pangeo-tmp/stb2145/SOSE/datasets/ds_tns.zarr'))\n",
    "ds_slt = xr.open_zarr(gcsfs.GCSMap('pangeo-tmp/stb2145/SOSE/datasets/ds_slt_wg.zarr'))\n",
    "ds_tmp = xr.open_zarr(gcsfs.GCSMap('pangeo-tmp/stb2145/SOSE/datasets/ds_tmp_wg.zarr'))\n",
    "ds_vel = xr.open_zarr(gcsfs.GCSMap('pangeo-tmp/stb2145/SOSE/datasets/ds_vel.zarr'))\n",
    "ds = xr.merge([ds_tns, ds_slt, ds_tmp, ds_vel])\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WG boundaries (80˚S, 62˚S, 65˚W, 30˚E)\n",
    "#WG model's boundaries after .roll(XC=700) (-77.87497˚S, -62.041634˚S; 295.08334W, 30.083334E)\n",
    "lower_lat = 0\n",
    "upper_lat = 95\n",
    "left_lon =  310\n",
    "right_lon = 880"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the boundaries\n",
    "lat_range = dict(YC=slice(lower_lat, upper_lat))\n",
    "lon_range = dict(XC=slice(left_lon, right_lon))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#set the boundaries\n",
    "lat_range_noface = dict(j=slice(lower_lat, upper_lat))\n",
    "lon_range_noface = dict(i=slice(left_lon, right_lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pref = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
