{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOSE Heat and Salt Budgets\n",
    "\n",
    "Evaluating the conservation of heat and salt content in the Southern Ocean State Estimate \n",
    "\n",
    "Author: [Ryan Abernathey](http://github.com/rabernat)\n",
    "\n",
    "![SOSE Logo](http://sose.ucsd.edu/images/SOSEpic.png)\n",
    "\n",
    "## Connect to Dask Cluster\n",
    "\n",
    "Below we create a dask cluster with 30 nodes to do our work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "logging.captureWarnings(True)\n",
    "logging.getLogger('py.warnings').setLevel(logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# When I `conda activate pangeo` --> `conda list` I see dask-kubernetes listed but when I `conda search dask-kubernetes` it says\n",
    "\n",
    "Loading channels: done\n",
    "\n",
    "PackagesNotFoundError: The following packages are not available from current channels:\n",
    "\n",
    "  - dask-kubernetes\n",
    "\n",
    "Current channels:\n",
    "\n",
    "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
    "  - https://repo.anaconda.com/pkgs/main/noarch\n",
    "  - https://repo.anaconda.com/pkgs/free/linux-64\n",
    "  - https://repo.anaconda.com/pkgs/free/noarch\n",
    "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
    "  - https://repo.anaconda.com/pkgs/r/noarch\n",
    "  - https://repo.anaconda.com/pkgs/pro/linux-64\n",
    "  - https://repo.anaconda.com/pkgs/pro/noarch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from dask.distributed import Client, progress\n",
    "from dask_kubernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=50)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ☝️ don't forget to follow along on the dashboard **"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import gcsfs\n",
    "import dask\n",
    "import dask.array as dsa\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open SOSE Dataset from Gyre"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ds = xr.open_zarr(gcsfs.GCSMap('pangeo-data/SOSE'))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, LocalCluster, progress\n",
    "cluster = LocalCluster(n_workers=4, threads_per_worker=8, ip='*')\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xr.open_zarr('/swot/SUM03/tmp/SOSE')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Size: %6.2F GB' % (ds.nbytes / 1e9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A trick for optimization: split the dataset into coordinates and data variables, and then drop the coordinates from the data variables.\n",
    "This makes it easier to align the data variables in arithmetic operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = ds.coords.to_dataset().reset_coords()\n",
    "dsr = ds.reset_coords(drop=True)\n",
    "dsr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Some Data\n",
    "\n",
    "As a sanity check, let's look at some values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews.operation.datashader import regrid\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%opts Image [width=900, height=400 colorbar=True] (cmap='Magma')\n",
    "\n",
    "hv_image = hv.Dataset(ds.THETA.where(ds.hFacC>0).rename('THETA')).to(hv.Image, kdims=['XC', 'YC'], dynamic=True)\n",
    "with dask.config.set(scheduler='single-threaded'):\n",
    "    display(regrid(hv_image, precompute=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create xgcm grid\n",
    "\n",
    "[Xgcm](http://xgcm.readthedocs.io) is a package which helps with the analysis of GCM data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgcm\n",
    "grid = xgcm.Grid(ds, periodic=('X', 'Y'))\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracer Budgets\n",
    "\n",
    "Here we will do the heat and salt budgets for SOSE. In integral form, these budgets can be written as\n",
    "\n",
    "$$\n",
    "\\mathcal{V} \\frac{\\partial S}{\\partial t} = G^S_{adv} + G^S_{diff} + G^S_{surf} + G^S_{linfs}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal{V} \\frac{\\partial \\theta}{\\partial t} = G^\\theta_{adv} + G^\\theta_{diff} + G^\\theta_{surf} + G^\\theta_{linfs} + G^\\theta_{sw}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{V}$ is the volume of the grid cell. The terms on the right-hand side are called _tendencies_. They add up to the total tendency (the left hand side).\n",
    "\n",
    "The first term is the convergence of advective fluxes. The second is the convergence of diffusive fluxes. The third is the explicit surface flux. The fourth is the correction due to the linear free-surface approximation. The fifth is shortwave penetration (only for temperature).\n",
    "\n",
    "### Flux Divergence\n",
    "\n",
    "First we define a function to calculate the convergence of the advective and diffusive fluxes, since this has to be repeated for both tracers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why did you use Neumann BC and not Dirichlet BC or another type of BC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tracer_flux_budget(suffix):\n",
    "    \"\"\"Calculate the convergence of fluxes of tracer `suffix` where \n",
    "    `suffix` is `TH` or `SLT`. Return a new xarray.Dataset.\"\"\"\n",
    "    conv_horiz_adv_flux = -(grid.diff(dsr['ADVx_' + suffix], 'X') +\n",
    "                          grid.diff(dsr['ADVy_' + suffix], 'Y')).rename('conv_horiz_adv_flux_' + suffix)\n",
    "    conv_horiz_diff_flux = -(grid.diff(dsr['DFxE_' + suffix], 'X') +\n",
    "                          grid.diff(dsr['DFyE_' + suffix], 'Y')).rename('conv_horiz_diff_flux_' + suffix)\n",
    "    # sign convention is opposite for vertical fluxes\n",
    "    conv_vert_adv_flux = grid.diff(dsr['ADVr_' + suffix], 'Z', boundary='fill').rename('conv_vert_adv_flux_' + suffix)\n",
    "    conv_vert_diff_flux = (grid.diff(dsr['DFrE_' + suffix], 'Z', boundary='fill') +\n",
    "                           grid.diff(dsr['DFrI_' + suffix], 'Z', boundary='fill') +\n",
    "                           grid.diff(dsr['KPPg_' + suffix], 'Z', boundary='fill')).rename('conv_vert_diff_flux_' + suffix)\n",
    "    \n",
    "    all_fluxes = [conv_horiz_adv_flux, conv_horiz_diff_flux, conv_vert_adv_flux, conv_vert_diff_flux]\n",
    "    conv_all_fluxes = sum(all_fluxes).rename('conv_total_flux_' + suffix)\n",
    "    \n",
    "    return xr.merge(all_fluxes + [conv_all_fluxes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of all converging adv/diff fluxes\n",
    "budget_slt = tracer_flux_budget('SLT')\n",
    "budget_slt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_th = tracer_flux_budget('TH')\n",
    "budget_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface Fluxes\n",
    "\n",
    "The surface fluxes are only active in the top model layer. We need to specify some constants to convert to the proper units and scale factors to convert to integral form. They also require some xarray special sauce to merge with the 3D variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "heat_capacity_cp = 3.994e3\n",
    "runit2mass = 1.035e3 #rho\n",
    "\n",
    "# treat the shortwave flux separately from the rest of the surface flux\n",
    "surf_flux_th = (dsr.TFLUX - dsr.oceQsw) * coords.rA / (heat_capacity_cp * runit2mass)\n",
    "surf_flux_th_sw = dsr.oceQsw * coords.rA / (heat_capacity_cp * runit2mass)\n",
    "\n",
    "# salt\n",
    "surf_flux_slt = dsr.SFLUX * coords.rA  / runit2mass\n",
    "lin_fs_correction_th = -(dsr.WTHMASS.isel(Zl=0, drop=True) * coords.rA)\n",
    "lin_fs_correction_slt = -(dsr.WSLTMASS.isel(Zl=0, drop=True) * coords.rA)\n",
    "\n",
    "# in order to align the surface fluxes with the rest of the 3D budget terms,\n",
    "# we need to give them a z coordinate. We can do that with this function\n",
    "def surface_to_3d(da):\n",
    "    da.coords['Z'] = dsr.Z[0]\n",
    "    return da.expand_dims(dim='Z', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortwave Flux\n",
    "\n",
    "Special treatment is needed for the shortwave flux, which penetrates into the interior of the water column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swfrac(coords, fact=1., jwtype=2):\n",
    "    \"\"\"Clone of MITgcm routine for computing sw flux penetration.\n",
    "    z: depth of output levels\"\"\"\n",
    "    \n",
    "    rfac = [0.58 , 0.62, 0.67, 0.77, 0.78]\n",
    "    a1 = [0.35 , 0.6  , 1.0  , 1.5  , 1.4]\n",
    "    a2 = [23.0 , 20.0 , 17.0 , 14.0 , 7.9 ]\n",
    "    \n",
    "    facz = fact * coords.Zl.sel(Zl=slice(0, -200))\n",
    "    j = jwtype-1\n",
    "    swdk = (rfac[j] * np.exp(facz / a1[j]) +\n",
    "            (1-rfac[j]) * np.exp(facz / a2[j]))\n",
    "            \n",
    "    return swdk.rename('swdk')\n",
    "\n",
    "_, swdown = xr.align(dsr.Zl, surf_flux_th_sw * swfrac(coords), join='left', )\n",
    "swdown = swdown.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can add the to the budget datasets and they will align correctly\n",
    "# into the top cell (lazily filling with NaN's elsewhere)\n",
    "budget_slt['surface_flux_conv_SLT'] = surface_to_3d(surf_flux_slt)\n",
    "budget_slt['lin_fs_correction_SLT'] = surface_to_3d(lin_fs_correction_slt)\n",
    "budget_slt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_th['surface_flux_conv_TH'] = surface_to_3d(surf_flux_th)\n",
    "budget_th['lin_fs_correction_TH'] = surface_to_3d(lin_fs_correction_th)\n",
    "budget_th['sw_flux_conv_TH'] = -grid.diff(swdown, 'Z', boundary='fill').fillna(0.)\n",
    "budget_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add it all up\n",
    "\n",
    "The total tendency should be given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathcal{V} \\frac{\\partial S}{\\partial t} = G^S_{adv} + G^S_{diff} + G^S_{surf} + G^S_{linfs}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathcal{V} \\frac{\\partial \\theta}{\\partial t} = G^\\theta_{adv} + G^\\theta_{diff} + G^\\theta_{surf} + G^\\theta_{linfs} + G^\\theta_{sw}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_slt['total_tendency_SLT'] = (budget_slt.conv_total_flux_SLT + \n",
    "                                    budget_slt.surface_flux_conv_SLT.fillna(0.) +\n",
    "                                    budget_slt.lin_fs_correction_SLT.fillna(0.))\n",
    "budget_slt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_th['total_tendency_TH'] = (budget_th.conv_total_flux_TH + \n",
    "                                  budget_th.surface_flux_conv_TH.fillna(0.) +\n",
    "                                  budget_th.lin_fs_correction_TH.fillna(0.) + \n",
    "                                  budget_th.sw_flux_conv_TH)\n",
    "budget_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Include the \"truth\"\n",
    "\n",
    "MITgcm keeps track of the true total tendence in the `TOT?TEND` variables.\n",
    "We can use these as check on our budget calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = (coords.drF * coords.rA * coords.hFacC)\n",
    "#client.scatter(volume)\n",
    "day2seconds = (24*60*60)**-1\n",
    "\n",
    "budget_th['total_tendency_TH_truth'] = dsr.TOTTTEND * volume * day2seconds\n",
    "budget_slt['total_tendency_SLT_truth'] = dsr.TOTSTEND * volume * day2seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Budget\n",
    "\n",
    "Now we do some checks to verify that the budget adds up.\n",
    "\n",
    "### Vertical and Horizontal Integrals of Budget\n",
    "\n",
    "We will take an average over the first 10 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slice = dict(time=slice(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_range = dict(YC=slice(-90,-30))\n",
    "\n",
    "def check_vertical(budget, suffix):\n",
    "    ds_chk = (budget[[f'total_tendency_{suffix}', f'total_tendency_{suffix}_truth']]\n",
    "              .sel(**valid_range).sum(dim=['Z', 'XC']).mean(dim='time'))\n",
    "    return ds_chk\n",
    "\n",
    "def check_horizontal(budget, suffix):\n",
    "    ds_chk = (budget[[f'total_tendency_{suffix}', f'total_tendency_{suffix}_truth']]\n",
    "              .sel(**valid_range).sum(dim=['YC', 'XC']).mean(dim='time'))\n",
    "    return ds_chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_vert = check_vertical(budget_th.isel(**time_slice), 'TH').load()\n",
    "th_vert.total_tendency_TH.plot(linewidth=2)\n",
    "th_vert.total_tendency_TH_truth.plot(linestyle='--', linewidth=2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_horiz = check_horizontal(budget_th.isel(**time_slice), 'TH').load()\n",
    "th_horiz.total_tendency_TH.plot(linewidth=2, y='Z')\n",
    "th_horiz.total_tendency_TH_truth.plot(linestyle='--', linewidth=2, y='Z')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "slt_vert = check_vertical(budget_slt.isel(**time_slice), 'SLT').load()\n",
    "slt_vert.total_tendency_SLT.plot(linewidth=2)\n",
    "slt_vert.total_tendency_SLT_truth.plot(linestyle='--', linewidth=2)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "slt_horiz = check_horizontal(budget_slt.isel(**time_slice), 'SLT').load()\n",
    "slt_horiz.total_tendency_SLT.plot(linewidth=2, y='Z')\n",
    "slt_horiz.total_tendency_SLT_truth.plot(linestyle='--', linewidth=2, y='Z')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram Analysis of Error\n",
    "\n",
    "The curves look the same. But how do we know whether our error is truly \"small\"?\n",
    "Answer: we compare the distribution of the error\n",
    "\n",
    "$$ P( G_{est} - G_{truth} ) $$\n",
    "\n",
    "to the distribution of the other terms in the equation, e.g. $P(G_{adv})$.\n",
    "\n",
    "First we try to determine the appropriate range for our histograms by looking at the maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_th.isel(**time_slice).max().load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_slt.isel(**time_slice).max().load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for histogram calculation\n",
    "th_range = (-2e7, 2e7)\n",
    "slt_range = (-1e8, 1e8)\n",
    "valid_region = dict(YC=slice(-90, -30))\n",
    "nbins = 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# budget errors\n",
    "error_th = budget_th.total_tendency_TH - budget_th.total_tendency_TH_truth\n",
    "error_slt = budget_slt.total_tendency_SLT - budget_slt.total_tendency_SLT_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate theta error histograms over the whole time range\n",
    "adv_hist_th, hbins_th = dsa.histogram(budget_th.conv_horiz_adv_flux_TH.sel(**valid_region).data,\n",
    "                                        bins=nbins, range=th_range)\n",
    "err_hist_th, hbins_th = dsa.histogram(error_th.sel(**valid_region).data,\n",
    "                                        bins=nbins, range=th_range)\n",
    "err_hist_th, adv_hist_th = dask.compute(err_hist_th, adv_hist_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_c_th = 0.5*(hbins_th[:-1] + hbins_th[1:])\n",
    "plt.semilogy(bin_c_th, adv_hist_th, label='Advective Tendency')\n",
    "plt.semilogy(bin_c_th, err_hist_th, label='Budget Residual')\n",
    "plt.legend()\n",
    "plt.title('THETA Budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate salt error histograms over the whole time range\n",
    "adv_hist_slt, hbins_slt = dsa.histogram(budget_slt.conv_horiz_adv_flux_SLT.sel(**valid_region).data,\n",
    "                                        bins=nbins, range=slt_range)\n",
    "err_hist_slt, hbins_slt = dsa.histogram(error_slt.sel(**valid_region).fillna(-9e13).data,\n",
    "                                        bins=nbins, range=slt_range)\n",
    "err_hist_slt, adv_hist_slt = dask.compute(err_hist_slt, adv_hist_slt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_c_slt = 0.5*(hbins_slt[:-1] + hbins_slt[1:])\n",
    "plt.semilogy(bin_c_slt, adv_hist_slt, label='Advective Tendency')\n",
    "plt.semilogy(bin_c_slt, err_hist_slt, label='Budget Residual')\n",
    "plt.title('SALT Budget')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These figures show that the error is extremely small compared to the other terms in the budget.\n",
    "\n",
    "## Weddell Sea Budget Timeseries\n",
    "\n",
    "Finally, we can do some science: compute the salinity budget for a specific region, such as the upper Weddell Sea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-00a41d56837b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m budget_slt_weddell = (budget_slt\n\u001b[1;32m      2\u001b[0m                         \u001b[0;34m.\u001b[0m\u001b[0msel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mYC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m68\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m290\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                         \u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'XC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'YC'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                         .load())\n\u001b[1;32m      5\u001b[0m \u001b[0mbudget_slt_weddell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pangeo/lib/python3.6/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;31m# evaluate all the dask arrays simultaneously\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mevaluated_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlazy_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlazy_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluated_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pangeo/lib/python3.6/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_keys__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0mpostcomputes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pangeo/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, dsk, keys, restrictions, loose_restrictions, resources, sync, asynchronous, direct, retries, priority, fifo_timeout, actors, **kwargs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2331\u001b[0m                 results = self.gather(packed, asynchronous=asynchronous,\n\u001b[0;32m-> 2332\u001b[0;31m                                       direct=direct)\n\u001b[0m\u001b[1;32m   2333\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pangeo/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, maxsize, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1654\u001b[0m             return self.sync(self._gather, futures, errors=errors,\n\u001b[1;32m   1655\u001b[0m                              \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                              asynchronous=asynchronous)\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoroutine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pangeo/lib/python3.6/site-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pangeo/lib/python3.6/site-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pangeo/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/pangeo/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "budget_slt_weddell = (budget_slt\n",
    "                        .sel(YC=slice(-80, -68), XC=slice(290, 360), Z=slice(0, -500))\n",
    "                        .sum(dim=('XC', 'YC', 'Z'))\n",
    "                        .load())\n",
    "budget_slt_weddell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "for v in budget_slt_weddell.data_vars:\n",
    "    budget_slt_weddell[v].rolling(time=30).mean().plot(label=v)\n",
    "plt.ylim([-4e7, 4e7])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Weddell Sea Salt Budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "for v in budget_slt_weddell.data_vars:\n",
    "    budget_slt_weddell[v].rolling(time=30).mean().plot(label=v)\n",
    "plt.ylim([-4e6, 4e6])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Weddell Sea Salt Budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These figures show that, while they advective terms are the largest ones in the budget, the actual variability in salinity is driven primarily by the surface fluxes.\n",
    "\n",
    "### Removing Climatlogy\n",
    "\n",
    "The timeseries is pretty short, but nevertheless we can try to remove the climatology to get a better idea of what drives the interannual variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_slt_weddell_mm = budget_slt_weddell.groupby('time.month').mean(dim='time')\n",
    "budget_slt_weddell_anom = budget_slt_weddell.groupby('time.month') - budget_slt_weddell_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "for v in budget_slt_weddell.data_vars:\n",
    "    budget_slt_weddell_anom[v].rolling(time=30).mean().plot(label=v)\n",
    "plt.ylim([-2.5e7, 2.5e7])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Weddell Sea Anomaly Salt Budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "for v in budget_slt_weddell.data_vars:\n",
    "    budget_slt_weddell_anom[v].rolling(time=30).mean().plot(label=v)\n",
    "plt.ylim([-2.5e6, 2.5e6])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Weddell Sea Anomaly Salt Budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monthly anomaly is also premoninantly driven by surface forcing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Doing the same for temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_th_weddell = (budget_th\n",
    "                        .sel(YC=slice(-80, -68), XC=slice(290, 360), Z=slice(0, -500))\n",
    "                        .sum(dim=('XC', 'YC', 'Z'))\n",
    "                        .load())\n",
    "budget_th_weddell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "for v in budget_th_weddell.data_vars:\n",
    "    budget_th_weddell[v].rolling(time=30).mean().plot(label=v)\n",
    "plt.ylim([-4e7, 4e7])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Weddell Sea Temperature Budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "for v in budget_th_weddell.data_vars:\n",
    "    budget_th_weddell[v].rolling(time=30).mean().plot(label=v)\n",
    "plt.ylim([-4e6, 4e6])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Weddell Sea Temperature Budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These figures show that, while they advective terms are the largest ones in the budget, the actual variability in salinity is driven primarily by the surface fluxes.\n",
    "\n",
    "### Removing Climatlogy (for temperature)\n",
    "\n",
    "The timeseries is pretty short, but nevertheless we can try to remove the climatology to get a better idea of what drives the interannual variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "budget_th_weddell_mm = budget_th_weddell.groupby('time.month').mean(dim='time')\n",
    "budget_th_weddell_anom = budget_th_weddell.groupby('time.month') - budget_th_weddell_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "for v in budget_th_weddell.data_vars:\n",
    "    budget_th_weddell_anom[v].rolling(time=30).mean().plot(label=v)\n",
    "plt.ylim([-2.5e7, 2.5e7])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Weddell Sea Anomaly Temperature Budget')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "for v in budget_th_weddell.data_vars:\n",
    "    budget_th_weddell_anom[v].rolling(time=30).mean().plot(label=v)\n",
    "plt.ylim([-2.5e6, 2.5e6])\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('Weddell Sea Anomaly Temperature Budget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing to Buoyancy\n",
    "by including $\\alpha$ and $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea water's Equation of State:\n",
    "$$ \\rho \\simeq \\rho_0 \\left [ 1 - \\alpha_0(1 - \\gamma_B z)(\\Theta) + \\beta_0 S_A \\right ] $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sst = budget_th.total_tendency_TH#.isel(Z=0)\n",
    "sss = budget_slt.total_tendency_SLT#.isel(Z=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (time: 438, Z: 42, YC: 320, XC: 2160)>\n",
       "dask.array<shape=(438, 42, 320, 2160), dtype=float32, chunksize=(1, 41, 319, 2159)>\n",
       "Coordinates:\n",
       "  * Z        (Z) float32 -5.0 -15.5 -27.0 -39.5 ... -5075.0 -5325.0 -5575.0\n",
       "  * time     (time) datetime64[ns] 2005-01-06 2005-01-11 ... 2010-12-31\n",
       "  * YC       (YC) float32 -77.87497 -77.7083 -77.54163 ... -24.874966 -24.7083\n",
       "  * XC       (XC) float32 0.083333336 0.25 0.4166667 ... 359.75 359.9167"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting practical salinity to absolute salinity\n",
    "sa = xr.apply_ufunc(gsw.SA_from_SP, sss, budget_slt.total_tendency_SLT.Z, budget_slt.total_tendency_SLT.XC, \n",
    "                    budget_slt.total_tendency_SLT.YC, output_dtypes=[sss.dtype], \n",
    "                    dask='parallelized').reset_coords(drop=True)\n",
    "sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (time: 438, Z: 42, YC: 320, XC: 2160)>\n",
       "dask.array<shape=(438, 42, 320, 2160), dtype=float32, chunksize=(1, 41, 319, 2159)>\n",
       "Coordinates:\n",
       "  * Z        (Z) float32 -5.0 -15.5 -27.0 -39.5 ... -5075.0 -5325.0 -5575.0\n",
       "  * time     (time) datetime64[ns] 2005-01-06 2005-01-11 ... 2010-12-31\n",
       "  * YC       (YC) float32 -77.87497 -77.7083 -77.54163 ... -24.874966 -24.7083\n",
       "  * XC       (XC) float32 0.083333336 0.25 0.4166667 ... 359.75 359.9167"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting potential temperature to conservative temperature\n",
    "ct = xr.apply_ufunc(gsw.CT_from_pt, sa, sst,\n",
    "                    output_dtypes=[sss.dtype],\n",
    "                    dask='parallelized').reset_coords(drop=True)\n",
    "ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (time: 438, Z: 42, YC: 320, XC: 2160)>\n",
       "dask.array<shape=(438, 42, 320, 2160), dtype=float32, chunksize=(1, 41, 319, 2159)>\n",
       "Coordinates:\n",
       "  * Z        (Z) float32 -5.0 -15.5 -27.0 -39.5 ... -5075.0 -5325.0 -5575.0\n",
       "  * time     (time) datetime64[ns] 2005-01-06 2005-01-11 ... 2010-12-31\n",
       "  * YC       (YC) float32 -77.87497 -77.7083 -77.54163 ... -24.874966 -24.7083\n",
       "  * XC       (XC) float32 0.083333336 0.25 0.4166667 ... 359.75 359.9167"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#thermal expansion coefficient\n",
    "alpha = xr.apply_ufunc(gsw.alpha, sa, ct, budget_th.Z,\n",
    "                    output_dtypes=[sst.dtype],\n",
    "                    dask='parallelized').reset_coords(drop=True)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xarray.DataArray (time: 438, Z: 42, YC: 320, XC: 2160)>\n",
       "dask.array<shape=(438, 42, 320, 2160), dtype=float32, chunksize=(1, 41, 319, 2159)>\n",
       "Coordinates:\n",
       "  * Z        (Z) float32 -5.0 -15.5 -27.0 -39.5 ... -5075.0 -5325.0 -5575.0\n",
       "  * time     (time) datetime64[ns] 2005-01-06 2005-01-11 ... 2010-12-31\n",
       "  * YC       (YC) float32 -77.87497 -77.7083 -77.54163 ... -24.874966 -24.7083\n",
       "  * XC       (XC) float32 0.083333336 0.25 0.4166667 ... 359.75 359.9167"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#haline contraction coefficient\n",
    "beta = xr.apply_ufunc(gsw.beta, sa, ct, budget_slt.Z,\n",
    "                      output_dtypes=[sss.dtype],\n",
    "                      dask='parallelized').reset_coords(drop=True)\n",
    "beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "focus on Weddell Sea buoyancy budget\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pangeo]",
   "language": "python",
   "name": "conda-env-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
